{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 93,
     "status": "ok",
     "timestamp": 1766135624847,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "iX9UfcbfmOeq"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "aborted",
     "timestamp": 1766135728136,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "cOs-sqfpvV6V"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "data_path = Path('ReDWeb_V1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1766135728141,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "EbszHn8uvIKD"
   },
   "outputs": [],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeS_bQjA2ygB"
   },
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103581,
     "status": "aborted",
     "timestamp": 1766135728142,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "m1dZcKVf2xv1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "\n",
    "class ReDWebDataset(Dataset):\n",
    "    def __init__(self, rgb_paths, depth_paths, transform=None):\n",
    "        self.rgb_paths = rgb_paths\n",
    "        self.depth_paths = depth_paths\n",
    "        self.transform = transform  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rgb_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = cv2.imread(self.rgb_paths[idx])\n",
    "        depth = cv2.imread(self.depth_paths[idx], cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "        if self.transform:\n",
    "            img, depth = self.transform(img, depth)\n",
    "        return img, depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103581,
     "status": "aborted",
     "timestamp": 1766135728142,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "2WOVeuNCvoWg"
   },
   "outputs": [],
   "source": [
    "filenames = os.listdir(data_path / 'Imgs')\n",
    "\n",
    "images_filenames = [data_path / 'Imgs' / filename for filename in filenames]\n",
    "depths_filenames = [data_path / 'RDs' / f\"{filename.split('.')[0]}.png\" for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103582,
     "status": "aborted",
     "timestamp": 1766135728143,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "a1wN_Gwn3TnY"
   },
   "outputs": [],
   "source": [
    "full_dataset = ReDWebDataset(images_filenames, depths_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5qr2CXko5dns"
   },
   "source": [
    "## Test/Train/Validation split\n",
    "\n",
    "- Train: 70% (2520 images)\n",
    "- Test: 15% (540 images)\n",
    "- Validation: 15% (540 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103582,
     "status": "aborted",
     "timestamp": 1766135728143,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "fpDaJ5NuatdF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices = list(range(len(full_dataset)))\n",
    "\n",
    "train_indices, temp_indices = train_test_split(\n",
    "    indices, test_size=0.30, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "val_indices, test_indices = train_test_split(\n",
    "    temp_indices, test_size=0.50, random_state=42, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103582,
     "status": "aborted",
     "timestamp": 1766135728144,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "ZE129cZY9Jsx"
   },
   "outputs": [],
   "source": [
    "train_imgs  = [images_filenames[i] for i in train_indices]\n",
    "train_depth = [depths_filenames[i] for i in train_indices]\n",
    "\n",
    "val_imgs  = [images_filenames[i] for i in val_indices]\n",
    "val_depth = [depths_filenames[i] for i in val_indices]\n",
    "\n",
    "test_imgs  = [images_filenames[i] for i in test_indices]\n",
    "test_depth = [depths_filenames[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tpm6L1Zc-NNb"
   },
   "source": [
    "## Augmenting function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103582,
     "status": "aborted",
     "timestamp": 1766135728144,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "jRVcEEg4-PrO"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def train_transform(img, depth):\n",
    "    if random.random() < 0.5:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        img[:,:,2] = img[:,:,2] * random.uniform(0.9, 1.1)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "    # 50% chance of flip\n",
    "    if random.random() < 0.5:\n",
    "        img = cv2.flip(img, 1)\n",
    "        depth = cv2.flip(depth, 1)\n",
    "\n",
    "    # Random resized crop\n",
    "    h, w = img.shape[:2]\n",
    "    scale = random.uniform(0.8, 1.0)  # keep 80–100% of image\n",
    "    new_h, new_w = int(scale*h), int(scale*w)\n",
    "    y = random.randint(0, h-new_h)\n",
    "    x = random.randint(0, w-new_w)\n",
    "\n",
    "    img = img[y:y+new_h, x:x+new_w]\n",
    "    depth = depth[y:y+new_h, x:x+new_w]\n",
    "\n",
    "    # Resize into 384x384\n",
    "    img = cv2.resize(img, (384, 384))\n",
    "    depth = cv2.resize(depth, (384, 384))\n",
    "\n",
    "    img = torch.from_numpy(img).permute(2,0,1).float() / 255.0\n",
    "    depth = torch.from_numpy(depth).float() / 255.0\n",
    "\n",
    "    return img, depth\n",
    "\n",
    "\n",
    "def val_transform(img, depth):\n",
    "    img = cv2.resize(img, (384, 384))\n",
    "    depth = cv2.resize(depth, (384, 384))\n",
    "    return torch.from_numpy(img).permute(2,0,1)/255.0, torch.from_numpy(depth)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103582,
     "status": "aborted",
     "timestamp": 1766135728144,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "VAGdeg_5bhku"
   },
   "outputs": [],
   "source": [
    "train_dataset = ReDWebDataset(train_imgs, train_depth, transform=train_transform)\n",
    "val_dataset   = ReDWebDataset(val_imgs, val_depth, transform=val_transform)\n",
    "test_dataset  = ReDWebDataset(test_imgs, test_depth, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103579,
     "status": "aborted",
     "timestamp": 1766135728144,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "LCL7GfN6AFsg"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_samples(dataset, num_samples=4):\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(num_samples*3, 6))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        idx = random.randint(0, len(dataset)-1)\n",
    "        img, depth = dataset[idx]  # get sample\n",
    "\n",
    "        # Convert tensor → numpy for plotting\n",
    "        if torch.is_tensor(img):\n",
    "            img_np = img.permute(1,2,0).cpu().numpy()\n",
    "        else:\n",
    "            img_np = img[:,:,::-1]  # BGR→RGB if still numpy\n",
    "\n",
    "        if torch.is_tensor(depth):\n",
    "            depth_np = depth.squeeze().cpu().numpy()\n",
    "        else:\n",
    "            depth_np = depth\n",
    "\n",
    "        # Show RGB\n",
    "        axes[0, i].imshow(img_np, cmap=None)\n",
    "        axes[0, i].set_title(\"RGB image\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        # Show depth\n",
    "        axes[1, i].imshow(depth_np, cmap=\"gray\")\n",
    "        axes[1, i].set_title(\"Relative Depth\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_samples(train_dataset, num_samples=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCziVm2vrKlE"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103575,
     "status": "aborted",
     "timestamp": 1766135728149,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "MZ2IJ_i-uFq5"
   },
   "outputs": [],
   "source": [
    "import depth_perception_model\n",
    "\n",
    "model = depth_perception_model.DepthEstimationModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103574,
     "status": "aborted",
     "timestamp": 1766135728149,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "Q0feaaL_vXVv"
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (3, 384,384))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cLrk1PWfAX-"
   },
   "source": [
    "## Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103574,
     "status": "aborted",
     "timestamp": 1766135728149,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "Qp-p2KGKixw1"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103572,
     "status": "aborted",
     "timestamp": 1766135728150,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "JL6ISSxofODb"
   },
   "outputs": [],
   "source": [
    "import loss_function\n",
    "\n",
    "model = depth_perception_model.DepthEstimationModel()\n",
    "\n",
    "criterion = loss_function.ranking_loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103572,
     "status": "aborted",
     "timestamp": 1766135728150,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "IkwkWtDZf9Ze"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    for img, depth in pbar:\n",
    "\n",
    "        img = img\n",
    "        depth = depth\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img)             # forward pass\n",
    "        loss = criterion(pred, depth) # compute loss\n",
    "        loss.backward()               # backprop\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # --- VALIDATION ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, depth in val_loader:\n",
    "            img = img\n",
    "            depth = depth\n",
    "            pred = model(img)\n",
    "            val_loss += criterion(pred, depth).item()\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103574,
     "status": "aborted",
     "timestamp": 1766135728152,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "tIN5MLdaogO4"
   },
   "outputs": [],
   "source": [
    "# To save model with optimizer\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': criterion,\n",
    "}, \"checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103573,
     "status": "aborted",
     "timestamp": 1766135728152,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "CwQq26vzokWo"
   },
   "outputs": [],
   "source": [
    "# To laod the model\n",
    "checkpoint = torch.load(\"checkpoint.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 103573,
     "status": "aborted",
     "timestamp": 1766135728153,
     "user": {
      "displayName": "Mahla Entezari",
      "userId": "03181671231896837240"
     },
     "user_tz": -210
    },
    "id": "7or3-UUfg72k"
   },
   "outputs": [],
   "source": [
    "for img, depth in test_loader:      # your DataLoader\n",
    "    img = img.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(img).cpu()     # (B,1,H,W)\n",
    "        # print(pred.shape)\n",
    "        # ranking_loss(pred, depth)\n",
    "\n",
    "    # visualize first 4 samples in batch\n",
    "    for i in range(4):\n",
    "        image_np = img[i].permute(1,2,0).cpu().numpy()        # (H,W,3)\n",
    "        depth_np = depth[i].squeeze().cpu().numpy()           # (H,W)\n",
    "        pred_np  = pred[i].squeeze().numpy()                  # (H,W)\n",
    "\n",
    "        plt.figure(figsize=(10,3))\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.title(\"Image\")\n",
    "        plt.imshow(image_np)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.title(\"Ground Truth Depth\")\n",
    "        plt.imshow(depth_np, cmap='inferno')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.title(\"Prediction\")\n",
    "        plt.imshow(pred_np, cmap='inferno')\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "w5dXXwIpQucj"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "main-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
